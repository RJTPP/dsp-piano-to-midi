{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4892b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Third-party deps used:\n",
    "# - soundfile (audio I/O)\n",
    "# - scipy (signal processing)\n",
    "# - pretty_midi (MIDI writing)\n",
    "# These must be available in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a0a02",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83727943",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class Params:\n",
    "    \"\"\"Global parameters for the Sing→MIDI pipeline.\n",
    "\n",
    "    All durations and sizes are validated; any derived values are computed on init.\n",
    "    \"\"\"\n",
    "\n",
    "    # Audio\n",
    "    sr: int = 48_000\n",
    "    frame: int = 2048\n",
    "    hop: int = 480\n",
    "\n",
    "    # Conditioning\n",
    "    hpf_cutoff: float = 90.0\n",
    "\n",
    "    # Smoothing\n",
    "    median_k: int = 7\n",
    "    ma_k: int = 3\n",
    "\n",
    "    # Segmentation / hysteresis\n",
    "    min_note_ms: int = 70\n",
    "    debounce_frames: int = 3\n",
    "    cents_tolerance: float = 35.0\n",
    "\n",
    "    # Key snapping\n",
    "    use_key_snap: bool = True\n",
    "    key_snap_cents: float = 40.0\n",
    "\n",
    "    # Onsets\n",
    "    onset_prom: float = 1.5\n",
    "\n",
    "    # Derived\n",
    "    min_note_frames: int = 0  # computed\n",
    "\n",
    "    # YIN band (Hz)\n",
    "    fmin_hz: float = 80.0\n",
    "    fmax_hz: float = 1000.0\n",
    "\n",
    "    # Voicing thresholds\n",
    "    min_confidence: float = 0.2\n",
    "    min_rms_dbfs: float = -50.0\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if self.sr <= 0:\n",
    "            raise ValueError(\"sr must be positive\")\n",
    "        if self.frame <= 0 or self.hop <= 0:\n",
    "            raise ValueError(\"frame and hop must be positive\")\n",
    "        if self.median_k < 1 or self.median_k % 2 == 0:\n",
    "            raise ValueError(\"median_k must be odd and >= 1\")\n",
    "        if self.ma_k < 1:\n",
    "            raise ValueError(\"ma_k must be >= 1\")\n",
    "        if self.debounce_frames < 1:\n",
    "            raise ValueError(\"debounce_frames must be >= 1\")\n",
    "        if not (0 < self.fmin_hz < self.fmax_hz):\n",
    "            raise ValueError(\"fmin_hz must be < fmax_hz and > 0\")\n",
    "        # Derived\n",
    "        self.min_note_frames = max(1, ceil((self.min_note_ms / 1000.0) * (self.sr / self.hop)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a2d30",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49923cd5",
   "metadata": {},
   "source": [
    "### Utilities: windows, stats, filters, smoothing, guards, peaks, timescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8de0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def hann_window(frame: int) -> np.ndarray:\n",
    "    \"\"\"Return a Hann window of length `frame`.\n",
    "\n",
    "    Uses periodic=False (symmetric Hann) suitable for STFT-style framing.\n",
    "    \"\"\"\n",
    "    if frame <= 0:\n",
    "        raise ValueError(\"frame must be positive\")\n",
    "    return np.hanning(frame)\n",
    "\n",
    "\n",
    "def frame_audio(x: np.ndarray, frame: int, hop: int) -> np.ndarray:\n",
    "    \"\"\"Slice 1D audio into frames with hop, returning shape (n_frames, frame).\n",
    "\n",
    "    Zero-pads the end so the last frame is complete.\n",
    "    \"\"\"\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"x must be 1D mono audio\")\n",
    "    n = len(x)\n",
    "    if n == 0:\n",
    "        return np.zeros((0, frame), dtype=x.dtype)\n",
    "    n_frames = 1 + int(np.ceil((n - frame) / hop)) if n > frame else 1\n",
    "    total = (n_frames - 1) * hop + frame\n",
    "    pad = total - n\n",
    "    if pad > 0:\n",
    "        x = np.pad(x, (0, pad))\n",
    "    strides = (x.strides[0] * hop, x.strides[0])\n",
    "    shape = (n_frames, frame)\n",
    "    return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides).copy()\n",
    "\n",
    "\n",
    "def frame_rms(frames: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Per-frame RMS for an array shaped (n_frames, frame_len).\"\"\"\n",
    "    return np.sqrt(np.mean(frames.astype(np.float64) ** 2, axis=1))\n",
    "\n",
    "\n",
    "def dbfs(val: float, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Convert linear amplitude to dBFS-like scale with epsilon clamp.\"\"\"\n",
    "    return 20.0 * np.log10(max(val, eps))\n",
    "\n",
    "\n",
    "def dc_blocker(x: np.ndarray, R: float = 0.995) -> np.ndarray:\n",
    "    \"\"\"Simple first-order DC blocker.\n",
    "\n",
    "    y[n] = x[n] - x[n-1] + R * y[n-1]\n",
    "    \"\"\"\n",
    "    y = np.zeros_like(x)\n",
    "    xm1 = 0.0\n",
    "    ym1 = 0.0\n",
    "    for i, xi in enumerate(x):\n",
    "        y[i] = xi - xm1 + R * ym1\n",
    "        xm1 = xi\n",
    "        ym1 = y[i]\n",
    "    return y\n",
    "\n",
    "\n",
    "def highpass_butter(x: np.ndarray, sr: int, cutoff_hz: float, order: int = 2) -> np.ndarray:\n",
    "    \"\"\"Zero-phase Butterworth high-pass filter.\n",
    "\n",
    "    - `cutoff_hz` ≤ 0 returns a copy of `x`.\n",
    "    - Uses `filtfilt` for zero-phase response and minimal distortion.\n",
    "    \"\"\"\n",
    "    if cutoff_hz <= 0:\n",
    "        return x.copy()\n",
    "    from scipy.signal import butter, filtfilt  # local import to keep top-level light\n",
    "    nyq = 0.5 * sr\n",
    "    norm = cutoff_hz / nyq\n",
    "    b, a = butter(order, norm, btype=\"highpass\")\n",
    "    return filtfilt(b, a, x, axis=-1)\n",
    "\n",
    "\n",
    "def median_filter(x: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Apply a 1D median filter of size `k` (odd) to `x`.\n",
    "\n",
    "    If `k<=1`, returns a copy of `x`. Even `k` is incremented to the next odd.\n",
    "    \"\"\"\n",
    "    if k <= 1:\n",
    "        return x.copy()\n",
    "    if k % 2 == 0:\n",
    "        k += 1\n",
    "    from scipy.signal import medfilt  # local import\n",
    "    return medfilt(x, kernel_size=k)\n",
    "\n",
    "\n",
    "def moving_average(x: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Centered moving average of width `k` using same-length convolution.\"\"\"\n",
    "    if k <= 1:\n",
    "        return x.copy()\n",
    "    k = max(1, int(k))\n",
    "    w = np.ones(k) / float(k)\n",
    "    y = np.convolve(x, w, mode=\"same\")\n",
    "    return y\n",
    "\n",
    "\n",
    "def band_clamp(x: np.ndarray, lo: float, hi: float) -> np.ndarray:\n",
    "    \"\"\"Replace values outside [lo, hi] with NaN, preserving in-band values.\"\"\"\n",
    "    out = x.copy()\n",
    "    mask = (out < lo) | (out > hi)\n",
    "    out[mask] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "def doubling_halving_guard(f0: np.ndarray, window: int = 5, cents_tol: float = 35.0) -> np.ndarray:\n",
    "    \"\"\"Correct x2/x0.5 octave jumps based on local median context.\"\"\"\n",
    "    out = f0.copy()\n",
    "    n = len(out)\n",
    "    if n == 0:\n",
    "        return out\n",
    "    for i in range(n):\n",
    "        if not np.isfinite(out[i]) or out[i] <= 0:\n",
    "            continue\n",
    "        lo = max(0, i - window)\n",
    "        hi = min(n, i + window + 1)\n",
    "        local = out[lo:hi]\n",
    "        local = local[np.isfinite(local) & (local > 0)]\n",
    "        if local.size < 3:\n",
    "            continue\n",
    "        med = float(np.median(local))\n",
    "        if med <= 0:\n",
    "            continue\n",
    "        r = out[i] / med\n",
    "        if 1.8 <= r <= 2.2:\n",
    "            cand = out[i] / 2.0\n",
    "        elif 0.45 <= r <= 0.55:\n",
    "            cand = out[i] * 2.0\n",
    "        else:\n",
    "            cand = out[i]\n",
    "        if cand != out[i]:\n",
    "            def cents(a: float, b: float) -> float:\n",
    "                return 1200.0 * math.log2(a / b)\n",
    "\n",
    "            err_old = abs(cents(out[i], med))\n",
    "            err_new = abs(cents(cand, med))\n",
    "            if err_new + 1e-6 < err_old and err_new <= cents_tol:\n",
    "                out[i] = cand\n",
    "    return out\n",
    "\n",
    "\n",
    "def find_peaks(signal: np.ndarray, min_distance: int = 1, threshold: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"Simple peak picker: local maxima above threshold with min distance.\"\"\"\n",
    "    x = signal\n",
    "    n = len(x)\n",
    "    if n < 3:\n",
    "        return np.array([], dtype=int)\n",
    "    greater_prev = x[1:-1] > x[:-2]\n",
    "    greater_next = x[1:-1] >= x[2:]\n",
    "    cand = np.where(greater_prev & greater_next)[0] + 1\n",
    "    cand = cand[x[cand] >= threshold]\n",
    "    if cand.size == 0:\n",
    "        return cand\n",
    "    order = np.argsort(x[cand])[::-1]\n",
    "    selected: list[int] = []\n",
    "    for idx in cand[order]:\n",
    "        if all(abs(idx - s) >= min_distance for s in selected):\n",
    "            selected.append(int(idx))\n",
    "    selected.sort()\n",
    "    return np.asarray(selected, dtype=int)\n",
    "\n",
    "\n",
    "def frame_to_time(frame_idx: int, hop: int, sr: int) -> float:\n",
    "    return (frame_idx * hop) / float(sr)\n",
    "\n",
    "\n",
    "def time_to_frame(time_s: float, hop: int, sr: int) -> int:\n",
    "    return int(round(time_s * sr / hop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fb618",
   "metadata": {},
   "source": [
    "### DSP: f0 (YIN), stabilization, onsets, hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265dbf4f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def f0_yin(\n",
    "    y: np.ndarray,\n",
    "    sr: int,\n",
    "    frame: int,\n",
    "    hop: int,\n",
    "    fmin_hz: float,\n",
    "    fmax_hz: float,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Estimate f0 using a light YIN implementation. Returns (f0_hz, conf, rms).\"\"\"\n",
    "    frames = frame_audio(y, frame=frame, hop=hop).astype(np.float64)\n",
    "    win = hann_window(frame)\n",
    "    frames *= win[None, :]\n",
    "    n_frames = frames.shape[0]\n",
    "    f0 = np.full(n_frames, np.nan, dtype=float)\n",
    "    rms = frame_rms(frames.astype(np.float64))\n",
    "\n",
    "    tmin = int(np.floor(sr / fmax_hz))\n",
    "    tmax = int(np.ceil(sr / fmin_hz))\n",
    "    tmax = min(tmax, frame - 2)\n",
    "    if tmax <= tmin:\n",
    "        return f0, np.zeros_like(f0), rms.astype(float)\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        x = frames[i]\n",
    "        x = x - np.mean(x)\n",
    "        d = _yin_difference(x, tmax)\n",
    "        cmnd = _yin_cmnd(d)\n",
    "        tau = _yin_absolute_threshold(cmnd, 0.1, tmin)\n",
    "        if tau == -1:\n",
    "            tau = int(np.argmin(cmnd[tmin:tmax]) + tmin)\n",
    "        if 1 <= tau < len(cmnd) - 1:\n",
    "            tau = _parabolic_interpolate(cmnd, tau)\n",
    "        if tau > 0:\n",
    "            f0[i] = sr / tau\n",
    "\n",
    "    conf = np.zeros_like(f0)\n",
    "    if rms.size > 0:\n",
    "        max_r = float(np.max(rms)) + 1e-12\n",
    "        conf = np.clip(rms / max_r, 0.0, 1.0)\n",
    "        low_energy = rms < (1e-3 * max_r)\n",
    "        f0[low_energy] = np.nan\n",
    "    return f0.astype(float), conf.astype(float), rms.astype(float)\n",
    "\n",
    "\n",
    "def _yin_difference(x: np.ndarray, tmax: int) -> np.ndarray:\n",
    "    N = len(x)\n",
    "    d = np.zeros(tmax, dtype=np.float64)\n",
    "    for tau in range(1, tmax):\n",
    "        diff = x[:-tau] - x[tau:]\n",
    "        d[tau] = np.dot(diff, diff)\n",
    "    d[0] = 0.0\n",
    "    return d\n",
    "\n",
    "\n",
    "def _yin_cmnd(d: np.ndarray) -> np.ndarray:\n",
    "    cmnd = np.zeros_like(d)\n",
    "    cmnd[0] = 1.0\n",
    "    running_sum = 0.0\n",
    "    for tau in range(1, len(d)):\n",
    "        running_sum += d[tau]\n",
    "        cmnd[tau] = d[tau] * tau / (running_sum + 1e-12)\n",
    "    return cmnd\n",
    "\n",
    "\n",
    "def _yin_absolute_threshold(cmnd: np.ndarray, thresh: float, start: int) -> int:\n",
    "    for tau in range(max(2, start), len(cmnd)):\n",
    "        if cmnd[tau] < thresh:\n",
    "            while tau + 1 < len(cmnd) and cmnd[tau + 1] < cmnd[tau]:\n",
    "                tau += 1\n",
    "            return tau\n",
    "    return -1\n",
    "\n",
    "\n",
    "def _parabolic_interpolate(y: np.ndarray, x: int) -> float:\n",
    "    xm1, x0, xp1 = y[x - 1], y[x], y[x + 1]\n",
    "    denom = (xm1 - 2 * x0 + xp1)\n",
    "    if abs(denom) < 1e-12:\n",
    "        return float(x)\n",
    "    delta = 0.5 * (xm1 - xp1) / denom\n",
    "    return float(x) + delta\n",
    "\n",
    "\n",
    "def forward_fill(x: np.ndarray) -> np.ndarray:\n",
    "    out = x.copy()\n",
    "    last = np.nan\n",
    "    for i, v in enumerate(out):\n",
    "        if np.isfinite(v):\n",
    "            last = v\n",
    "        else:\n",
    "            out[i] = last\n",
    "    if not np.isfinite(out[0]):\n",
    "        next_val = np.nan\n",
    "        for i in range(len(out) - 1, -1, -1):\n",
    "            if np.isfinite(out[i]):\n",
    "                next_val = out[i]\n",
    "            else:\n",
    "                out[i] = next_val\n",
    "    return out\n",
    "\n",
    "\n",
    "def stabilize_f0(\n",
    "    f0_hz: np.ndarray,\n",
    "    fmin_hz: float,\n",
    "    fmax_hz: float,\n",
    "    median_k: int,\n",
    "    ma_k: int,\n",
    "    guard_window: int = 5,\n",
    "    cents_tol: float = 35.0,\n",
    ") -> np.ndarray:\n",
    "    x = band_clamp(f0_hz, fmin_hz, fmax_hz)\n",
    "    x = median_filter(np.nan_to_num(x, nan=0.0), k=median_k)\n",
    "    x[x <= 0] = np.nan\n",
    "    if ma_k > 1:\n",
    "        xf = forward_fill(x)\n",
    "        xa = moving_average(xf, k=ma_k)\n",
    "        x = np.where(np.isfinite(x), xa, x)\n",
    "    x = doubling_halving_guard(x, window=guard_window, cents_tol=cents_tol)\n",
    "    return x\n",
    "\n",
    "\n",
    "def spectral_flux_onsets(\n",
    "    y: np.ndarray,\n",
    "    sr: int,\n",
    "    frame: int,\n",
    "    hop: int,\n",
    "    prom: float = 1.5,\n",
    "    min_distance_frames: int = 2,\n",
    ") -> np.ndarray:\n",
    "    frames = frame_audio(y, frame=frame, hop=hop).astype(float)\n",
    "    win = hann_window(frame)\n",
    "    frames *= win[None, :]\n",
    "    n_fft = int(2 ** np.ceil(np.log2(frame)))\n",
    "    mag = np.abs(np.fft.rfft(frames, n=n_fft))\n",
    "    diff = np.maximum(0.0, mag[1:, :] - mag[:-1, :])\n",
    "    flux = np.sum(diff, axis=1)\n",
    "    if flux.size == 0:\n",
    "        return np.array([], dtype=int)\n",
    "    thr = np.median(flux) * prom\n",
    "    peaks = find_peaks(flux, min_distance=min_distance_frames, threshold=thr)\n",
    "    return peaks + 1  # shift by 1 frame due to diff\n",
    "\n",
    "\n",
    "def hysteresis_round(\n",
    "    midi_float: np.ndarray,\n",
    "    debounce_frames: int,\n",
    "    cents_tolerance: float,\n",
    ") -> np.ndarray:\n",
    "    out = np.full_like(midi_float, np.nan, dtype=float)\n",
    "    current: Optional[int] = None\n",
    "    streak_note: Optional[int] = None\n",
    "    streak_len = 0\n",
    "\n",
    "    def cents_err(nf: float, ni: int) -> float:\n",
    "        return 100.0 * abs(nf - float(ni))\n",
    "\n",
    "    for i, nf in enumerate(midi_float):\n",
    "        if not np.isfinite(nf):\n",
    "            out[i] = np.nan\n",
    "            streak_note = None\n",
    "            streak_len = 0\n",
    "            continue\n",
    "        cand = int(np.round(nf))\n",
    "        if current is None:\n",
    "            if cents_err(nf, cand) <= cents_tolerance:\n",
    "                streak_note = cand if streak_note is None else streak_note\n",
    "                if streak_note == cand:\n",
    "                    streak_len += 1\n",
    "                else:\n",
    "                    streak_note = cand\n",
    "                    streak_len = 1\n",
    "                if streak_len >= debounce_frames:\n",
    "                    current = cand\n",
    "            out[i] = np.nan if current is None else float(current)\n",
    "            continue\n",
    "\n",
    "        if cand == current or cents_err(nf, current) <= cents_tolerance:\n",
    "            streak_note = None\n",
    "            streak_len = 0\n",
    "            out[i] = float(current)\n",
    "            continue\n",
    "\n",
    "        if cents_err(nf, cand) <= cents_tolerance:\n",
    "            if streak_note == cand:\n",
    "                streak_len += 1\n",
    "            else:\n",
    "                streak_note = cand\n",
    "                streak_len = 1\n",
    "            if streak_len >= debounce_frames:\n",
    "                current = cand\n",
    "                streak_note = None\n",
    "                streak_len = 0\n",
    "        else:\n",
    "            streak_note = None\n",
    "            streak_len = 0\n",
    "        out[i] = float(current)\n",
    "    return out\n",
    "\n",
    "\n",
    "def segments_from_notes(\n",
    "    note_series: np.ndarray,\n",
    "    min_note_frames: int,\n",
    ") -> list[tuple[int, int, int]]:\n",
    "    n = len(note_series)\n",
    "    segments: list[tuple[int, int, int]] = []\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if not np.isfinite(note_series[i]):\n",
    "            i += 1\n",
    "            continue\n",
    "        midi = int(note_series[i])\n",
    "        j = i + 1\n",
    "        while j < n and np.isfinite(note_series[j]) and int(note_series[j]) == midi:\n",
    "            j += 1\n",
    "        start, end = i, j\n",
    "        segments.append((midi, start, end))\n",
    "        i = j\n",
    "\n",
    "    merged: list[tuple[int, int, int]] = []\n",
    "    for seg in segments:\n",
    "        if not merged:\n",
    "            merged.append(seg)\n",
    "            continue\n",
    "        midi, s, e = seg\n",
    "        prev_m, ps, pe = merged[-1]\n",
    "        if e - s < min_note_frames:\n",
    "            if midi == prev_m:\n",
    "                merged[-1] = (prev_m, ps, e)\n",
    "                continue\n",
    "        merged.append(seg)\n",
    "\n",
    "    final: list[tuple[int, int, int]] = []\n",
    "    for idx, (m, s, e) in enumerate(merged):\n",
    "        if e - s >= min_note_frames:\n",
    "            final.append((m, s, e))\n",
    "            continue\n",
    "        attached = False\n",
    "        if idx > 0 and merged[idx - 1][0] == m:\n",
    "            pm, ps, pe = final[-1]\n",
    "            final[-1] = (pm, ps, e)\n",
    "            attached = True\n",
    "        elif idx + 1 < len(merged) and merged[idx + 1][0] == m:\n",
    "            nm, ns, ne = merged[idx + 1]\n",
    "            final.append((m, s, ne))\n",
    "            merged[idx + 1] = (nm, ne, ne)\n",
    "            attached = True\n",
    "        if not attached:\n",
    "            pass\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae37ebc8",
   "metadata": {},
   "source": [
    "### Music helpers: Hz↔MIDI, basic key detection/snapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3b114",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def hz_to_midi(f_hz: np.ndarray | float) -> np.ndarray | float:\n",
    "    \"\"\"Convert frequency in Hz to MIDI number (float).\"\"\"\n",
    "    if isinstance(f_hz, np.ndarray):\n",
    "        out = 69.0 + 12.0 * np.log2(np.asarray(f_hz) / 440.0)\n",
    "        out[~np.isfinite(out)] = np.nan\n",
    "        return out\n",
    "    if not math.isfinite(f_hz) or f_hz <= 0:\n",
    "        return float(\"nan\")\n",
    "    return 69.0 + 12.0 * math.log2(f_hz / 440.0)\n",
    "\n",
    "\n",
    "def midi_to_hz(n: float) -> float:\n",
    "    return 440.0 * (2.0 ** ((n - 69.0) / 12.0))\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class KeyEstimate:\n",
    "    tonic: int  # 0..11 (C=0)\n",
    "    mode: str   # 'major' or 'minor'\n",
    "    score: float\n",
    "\n",
    "\n",
    "MAJOR_KS = np.array([6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88])\n",
    "MINOR_KS = np.array([6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17])\n",
    "\n",
    "KEY_NAME_TO_INT = {\n",
    "    \"C\": 0,\n",
    "    \"C#\": 1,\n",
    "    \"DB\": 1,\n",
    "    \"D\": 2,\n",
    "    \"D#\": 3,\n",
    "    \"EB\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5,\n",
    "    \"F#\": 6,\n",
    "    \"GB\": 6,\n",
    "    \"G\": 7,\n",
    "    \"G#\": 8,\n",
    "    \"AB\": 8,\n",
    "    \"A\": 9,\n",
    "    \"A#\": 10,\n",
    "    \"BB\": 10,\n",
    "    \"B\": 11,\n",
    "}\n",
    "\n",
    "\n",
    "def pitch_class_hist(midi_notes: Iterable[int]) -> np.ndarray:\n",
    "    pcs = np.zeros(12, dtype=float)\n",
    "    for n in midi_notes:\n",
    "        pcs[int(n) % 12] += 1.0\n",
    "    if pcs.sum() > 0:\n",
    "        pcs /= pcs.sum()\n",
    "    return pcs\n",
    "\n",
    "\n",
    "def estimate_key(midi_notes: Iterable[int]) -> KeyEstimate | None:\n",
    "    notes = list(midi_notes)\n",
    "    if not notes:\n",
    "        return None\n",
    "    hist = pitch_class_hist(notes)\n",
    "    best_score = -1.0\n",
    "    best: KeyEstimate | None = None\n",
    "    for tonic in range(12):\n",
    "        maj_t = np.roll(MAJOR_KS, tonic)\n",
    "        min_t = np.roll(MINOR_KS, tonic)\n",
    "        smaj = float(np.dot(hist, maj_t))\n",
    "        smin = float(np.dot(hist, min_t))\n",
    "        if smaj > best_score:\n",
    "            best_score = smaj\n",
    "            best = KeyEstimate(tonic=tonic, mode=\"major\", score=smaj)\n",
    "        if smin > best_score:\n",
    "            best_score = smin\n",
    "            best = KeyEstimate(tonic=tonic, mode=\"minor\", score=smin)\n",
    "    return best\n",
    "\n",
    "\n",
    "def snap_to_key(n: int, key: KeyEstimate) -> int:\n",
    "    if key.mode == \"major\":\n",
    "        scale = {0, 2, 4, 5, 7, 9, 11}\n",
    "    else:\n",
    "        scale = {0, 2, 3, 5, 7, 8, 10}\n",
    "    pc = n % 12\n",
    "    if pc in scale:\n",
    "        return n\n",
    "    candidates = []\n",
    "    for off in range(-2, 3):\n",
    "        pc2 = (pc + off) % 12\n",
    "        if pc2 in scale:\n",
    "            candidates.append((abs(off), n + off))\n",
    "    if not candidates:\n",
    "        return n\n",
    "    candidates.sort()\n",
    "    return candidates[0][1]\n",
    "\n",
    "\n",
    "def key_override_to_estimate(value: object) -> KeyEstimate | None:\n",
    "    if isinstance(value, KeyEstimate):\n",
    "        return value\n",
    "    tonic_name: str | None = None\n",
    "    mode_name: str | None = None\n",
    "    if isinstance(value, tuple) and len(value) == 2:\n",
    "        tonic_name, mode_name = value\n",
    "    elif isinstance(value, str):\n",
    "        parts = value.replace(\"-\", \" \").replace(\"\\t\", \" \").split()\n",
    "        if len(parts) >= 2:\n",
    "            tonic_name, mode_name = parts[0], parts[1]\n",
    "    if tonic_name is None or mode_name is None:\n",
    "        return None\n",
    "    tonic_key = KEY_NAME_TO_INT.get(tonic_name.upper())\n",
    "    if tonic_key is None:\n",
    "        return None\n",
    "    mode_norm = mode_name.strip().lower()\n",
    "    if mode_norm in {\"maj\", \"major\", \"ionian\"}:\n",
    "        mode = \"major\"\n",
    "    elif mode_norm in {\"min\", \"minor\", \"aeolian\"}:\n",
    "        mode = \"minor\"\n",
    "    else:\n",
    "        return None\n",
    "    return KeyEstimate(tonic=tonic_key, mode=mode, score=float(\"inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09bc92f",
   "metadata": {},
   "source": [
    "### IO: audio load/condition, MIDI writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962fc71c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass as _dataclass_for_audio\n",
    "\n",
    "\n",
    "@_dataclass_for_audio(slots=True)\n",
    "class Audio:\n",
    "    y: np.ndarray  # mono float32\n",
    "    sr: int\n",
    "\n",
    "\n",
    "def load_mono(path: str, sr: int) -> Audio:\n",
    "    \"\"\"Load audio file, resample to `sr`, and return mono float32 array in [-1,1].\"\"\"\n",
    "    import soundfile as sf\n",
    "    from scipy.signal import resample_poly\n",
    "    y, file_sr = sf.read(path, always_2d=True)\n",
    "    y = y.astype(np.float32)\n",
    "    y = np.mean(y, axis=1)\n",
    "    if file_sr != sr:\n",
    "        from math import gcd\n",
    "        g = gcd(file_sr, sr)\n",
    "        up = sr // g\n",
    "        down = file_sr // g\n",
    "        y = resample_poly(y, up, down)\n",
    "    return Audio(y=y.astype(np.float32, copy=False), sr=sr)\n",
    "\n",
    "\n",
    "def save_wav(path: str, audio: Audio) -> None:\n",
    "    import soundfile as sf\n",
    "    sf.write(path, audio.y, audio.sr, subtype=\"PCM_16\")\n",
    "\n",
    "\n",
    "def normalize_rms(y: np.ndarray, target_dbfs: float = -20.0, eps: float = 1e-9) -> np.ndarray:\n",
    "    rms = float(np.sqrt(np.mean(np.square(y), dtype=np.float64)))\n",
    "    if rms < eps:\n",
    "        return y.copy()\n",
    "    current_dbfs = 20.0 * np.log10(max(rms, eps))\n",
    "    gain_db = target_dbfs - current_dbfs\n",
    "    gain = 10.0 ** (gain_db / 20.0)\n",
    "    out = y * gain\n",
    "    max_abs = float(np.max(np.abs(out)))\n",
    "    if max_abs > 1.0:\n",
    "        out /= max_abs\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def condition(y: np.ndarray, sr: int, hpf_cutoff: float) -> np.ndarray:\n",
    "    y = dc_blocker(y)\n",
    "    y = highpass_butter(y, sr=sr, cutoff_hz=hpf_cutoff, order=2)\n",
    "    return y.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def velocity_from_rms(rms: float, rms_min: float, rms_max: float) -> int:\n",
    "    lo, hi = 40, 100\n",
    "    if rms_max <= rms_min:\n",
    "        return int((lo + hi) // 2)\n",
    "    t = (rms - rms_min) / (rms_max - rms_min)\n",
    "    v = int(np.clip(lo + t * (hi - lo), lo, hi))\n",
    "    return v\n",
    "\n",
    "\n",
    "def write_midi(\n",
    "    path: str,\n",
    "    segments: list[tuple[int, float, float, float]],\n",
    "    program: int = 0,\n",
    "    tempo_bpm: float | None = None,\n",
    ") -> None:\n",
    "    import pretty_midi\n",
    "    initial_tempo = float(tempo_bpm) if tempo_bpm else 120.0\n",
    "    pm = pretty_midi.PrettyMIDI(initial_tempo=initial_tempo)\n",
    "    inst = pretty_midi.Instrument(program=program)\n",
    "    if segments:\n",
    "        rms_vals = [s[3] for s in segments]\n",
    "        rmin, rmax = min(rms_vals), max(rms_vals)\n",
    "    else:\n",
    "        rmin = rmax = 0.0\n",
    "    for midi, s, e, rms in segments:\n",
    "        vel = velocity_from_rms(rms, rmin, rmax)\n",
    "        note = pretty_midi.Note(start=float(s), end=float(e), pitch=int(midi), velocity=int(vel))\n",
    "        inst.notes.append(note)\n",
    "    pm.instruments.append(inst)\n",
    "    pm.write(path)\n",
    "\n",
    "\n",
    "def voice_mask_from_confidence(\n",
    "    f0_hz: np.ndarray,\n",
    "    voiced_conf: np.ndarray | None,\n",
    "    frame_rms_vals: np.ndarray,\n",
    "    min_confidence: float,\n",
    "    min_rms_dbfs: float,\n",
    ") -> np.ndarray:\n",
    "    eps = 1e-12\n",
    "    ref = max(np.max(frame_rms_vals), eps)\n",
    "    db = 20.0 * np.log10(np.clip(frame_rms_vals / ref, eps, None))\n",
    "    rms_ok = db >= min_rms_dbfs\n",
    "    if voiced_conf is None:\n",
    "        conf_ok = np.isfinite(f0_hz)\n",
    "    else:\n",
    "        conf_ok = voiced_conf >= min_confidence\n",
    "    return rms_ok & conf_ok & np.isfinite(f0_hz) & (f0_hz > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3a9aa",
   "metadata": {},
   "source": [
    "## Pipeline (full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4f567",
   "metadata": {},
   "source": [
    "### Pipeline: step-by-step functions and a convenience runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a6490",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_pipeline_features(y: np.ndarray, params: Params) -> dict:\n",
    "    \"\"\"Run all core steps and return intermediates for inspection.\"\"\"\n",
    "    sr = params.sr\n",
    "    # f0 + confidence + frame rms\n",
    "    f0_hz, conf, rms_vals = f0_yin(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        frame=params.frame,\n",
    "        hop=params.hop,\n",
    "        fmin_hz=params.fmin_hz,\n",
    "        fmax_hz=params.fmax_hz,\n",
    "    )\n",
    "    # voice mask\n",
    "    voiced_mask = voice_mask_from_confidence(\n",
    "        f0_hz=f0_hz,\n",
    "        voiced_conf=conf,\n",
    "        frame_rms_vals=rms_vals,\n",
    "        min_confidence=params.min_confidence,\n",
    "        min_rms_dbfs=params.min_rms_dbfs,\n",
    "    )\n",
    "    f0_hz_voiced = f0_hz.copy()\n",
    "    f0_hz_voiced[~voiced_mask] = np.nan\n",
    "\n",
    "    # stabilized f0\n",
    "    f0_stable = stabilize_f0(\n",
    "        f0_hz=f0_hz_voiced,\n",
    "        fmin_hz=params.fmin_hz,\n",
    "        fmax_hz=params.fmax_hz,\n",
    "        median_k=params.median_k,\n",
    "        ma_k=params.ma_k,\n",
    "        guard_window=5,\n",
    "        cents_tol=params.cents_tolerance,\n",
    "    )\n",
    "\n",
    "    # onsets (optional for debug)\n",
    "    onsets = spectral_flux_onsets(\n",
    "        y=y,\n",
    "        sr=sr,\n",
    "        frame=params.frame,\n",
    "        hop=params.hop,\n",
    "        prom=params.onset_prom,\n",
    "    )\n",
    "\n",
    "    # map to MIDI float\n",
    "    midi_float = hz_to_midi(f0_stable)\n",
    "\n",
    "    # hysteresis rounding and frame segments\n",
    "    note_series = hysteresis_round(midi_float, params.debounce_frames, params.cents_tolerance)\n",
    "    seg_idx = segments_from_notes(note_series, min_note_frames=params.min_note_frames)\n",
    "\n",
    "    # key estimate\n",
    "    midi_list = [m for (m, s, e) in seg_idx]\n",
    "    key = estimate_key(midi_list) if (params.use_key_snap and midi_list) else None\n",
    "\n",
    "    # frame RMS for velocity\n",
    "    frames = frame_audio(y, frame=params.frame, hop=params.hop)\n",
    "    win = hann_window(params.frame)\n",
    "    frames_win = frames * win[None, :]\n",
    "    rms_frames = frame_rms(frames_win)\n",
    "\n",
    "    return {\n",
    "        \"f0_hz\": f0_hz,\n",
    "        \"conf\": conf,\n",
    "        \"frame_rms\": rms_vals,\n",
    "        \"voiced_mask\": voiced_mask,\n",
    "        \"f0_stable\": f0_stable,\n",
    "        \"onsets\": onsets,\n",
    "        \"midi_float\": midi_float,\n",
    "        \"note_series\": note_series,\n",
    "        \"seg_idx\": seg_idx,\n",
    "        \"key\": key,\n",
    "        \"rms_frames\": rms_frames,\n",
    "    }\n",
    "\n",
    "\n",
    "def segments_to_timed(\n",
    "    seg_idx: list[tuple[int, int, int]],\n",
    "    rms_frames: np.ndarray,\n",
    "    params: Params,\n",
    ") -> list[tuple[int, float, float, float]]:\n",
    "    segments: list[tuple[int, float, float, float]] = []\n",
    "    for midi, s_idx, e_idx in seg_idx:\n",
    "        midi_eff = midi\n",
    "        start_s = frame_to_time(s_idx, hop=params.hop, sr=params.sr)\n",
    "        end_s = frame_to_time(e_idx, hop=params.hop, sr=params.sr)\n",
    "        if e_idx > s_idx and e_idx <= len(rms_frames):\n",
    "            rms_med = float(np.median(rms_frames[s_idx:e_idx]))\n",
    "        else:\n",
    "            rms_med = 0.0\n",
    "        segments.append((int(midi_eff), float(start_s), float(end_s), float(rms_med)))\n",
    "    return segments\n",
    "\n",
    "\n",
    "def apply_key_snap(segments: list[tuple[int, float, float, float]], key: KeyEstimate | None) -> list[tuple[int, float, float, float]]:\n",
    "    if key is None:\n",
    "        return segments\n",
    "    out = []\n",
    "    for midi, s, e, rms in segments:\n",
    "        out.append((snap_to_key(midi, key), s, e, rms))\n",
    "    return out\n",
    "\n",
    "\n",
    "def wav_to_midi_simple(in_wav: str, out_mid: str, params: Params) -> dict:\n",
    "    \"\"\"Convenience: full WAV→MIDI run, returns intermediates plus output path.\"\"\"\n",
    "    audio = load_mono(in_wav, sr=params.sr)\n",
    "    y0 = audio.y\n",
    "    y = condition(y0, sr=audio.sr, hpf_cutoff=params.hpf_cutoff)\n",
    "    y = normalize_rms(y)\n",
    "\n",
    "    feats = extract_pipeline_features(y, params)\n",
    "    seg_idx = feats[\"seg_idx\"]\n",
    "    key = feats[\"key\"]\n",
    "    segments = segments_to_timed(seg_idx, feats[\"rms_frames\"], params)\n",
    "    if key is not None and params.use_key_snap:\n",
    "        segments = apply_key_snap(segments, key)\n",
    "    write_midi(out_mid, segments)\n",
    "    feats[\"segments\"] = segments\n",
    "    feats[\"out_mid\"] = out_mid\n",
    "    feats[\"audio\"] = y\n",
    "    feats[\"sr\"] = params.sr\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d031d",
   "metadata": {},
   "source": [
    "### Demo Run: CLI summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8749dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_summary(feats: dict, params: Params) -> None:\n",
    "    f0 = feats[\"f0_hz\"]\n",
    "    conf = feats[\"conf\"]\n",
    "    rms_vals = feats[\"frame_rms\"]\n",
    "    voiced = feats[\"voiced_mask\"]\n",
    "    f0_stable = feats[\"f0_stable\"]\n",
    "    onsets = feats[\"onsets\"]\n",
    "    seg_idx = feats[\"seg_idx\"]\n",
    "    key = feats[\"key\"]\n",
    "    segments = feats.get(\"segments\", [])\n",
    "\n",
    "    n_frames = len(f0)\n",
    "    n_voiced = int(np.sum(voiced))\n",
    "    voiced_pct = 100.0 * n_voiced / max(1, n_frames)\n",
    "\n",
    "    def mednan(a: np.ndarray) -> float:\n",
    "        a = a[np.isfinite(a)]\n",
    "        return float(np.median(a)) if a.size else float(\"nan\")\n",
    "\n",
    "    print(\"Frames:\", n_frames, \" Hop:\", params.hop, \" Frame:\", params.frame, \" SR:\", params.sr)\n",
    "    print(\"RMS median:\", round(float(np.median(rms_vals)), 6))\n",
    "    print(\"Voiced frames:\", n_voiced, f\"({voiced_pct:.1f}%)\")\n",
    "    print(\"f0 median (raw):\", round(mednan(f0), 2), \"Hz\")\n",
    "    print(\"f0 median (stable):\", round(mednan(f0_stable), 2), \"Hz\")\n",
    "    print(\"Onsets detected:\", int(len(onsets)))\n",
    "    print(\"Frame segments:\", int(len(seg_idx)))\n",
    "    if key is not None:\n",
    "        tonic_names = [\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"]\n",
    "        print(\"Estimated key:\", tonic_names[key.tonic], key.mode, f\"(score={key.score:.3f})\")\n",
    "    print(\"Notes exported:\", int(len(segments)))\n",
    "    if segments:\n",
    "        print(\"First 5 notes (midi, start, end, rms):\")\n",
    "        for row in segments[:5]:\n",
    "            print(\"  \", row)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Simple CLI for quick runs; you can also run cells interactively.\n",
    "#     cli = argparse.ArgumentParser(description=\"Sing→MIDI simple runner (notebook-style)\")\n",
    "#     cli.add_argument(\"input\", type=str, help=\"Input WAV path\")\n",
    "#     cli.add_argument(\"--out\", type=str, default=None, help=\"Output MIDI path (default: input.mid)\")\n",
    "#     cli.add_argument(\"--sr\", type=int, default=48000)\n",
    "#     args = cli.parse_args()\n",
    "#     params = Params(sr=args.sr)\n",
    "#     in_wav = args.input\n",
    "#     out_mid = args.out or str(Path(in_wav).with_suffix(\".mid\"))\n",
    "#     feats = wav_to_midi_simple(in_wav, out_mid, params)\n",
    "#     print(f\"Wrote: {Path(out_mid).resolve()}\")\n",
    "#     _print_summary(feats, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b530cd",
   "metadata": {},
   "source": [
    "## Pipeline (states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3d87e",
   "metadata": {},
   "source": [
    "### Quick Start (Notebook cell): set INPUT_WAV and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076236f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"audio\": {\n",
    "        \"example\": \"examples/example.mp3\",\n",
    "    },\n",
    "    \"midi_gt\": {\n",
    "        \"example\": \"examples/example.midi\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example interactive usage:\n",
    "# - Set INPUT_WAV to your audio file path.\n",
    "# - Optionally set OUT_MIDI or leave as None to default to INPUT_WAV with .mid.\n",
    "# - Tweak Params(), re-run this cell to iterate.\n",
    "#\n",
    "\n",
    "selection = \"example\"\n",
    "\n",
    "INPUT_WAV = datasets[\"audio\"][selection]\n",
    "\n",
    "OUT_MIDI: str | None = None\n",
    "params = Params()\n",
    "\n",
    "GT_MIDI: str | None = None\n",
    "GT_MIDI = datasets[\"midi_gt\"].get(selection, None)\n",
    "\n",
    "# if INPUT_WAV:\n",
    "#     out_mid = OUT_MIDI or str(Path(INPUT_WAV).with_suffix(\".mid\"))\n",
    "#     feats = wav_to_midi_simple(INPUT_WAV, out_mid, params)\n",
    "#     print(f\"Wrote: {Path(out_mid).resolve()}\")\n",
    "#     _print_summary(feats, params)\n",
    "\n",
    "if INPUT_WAV: print(Path(INPUT_WAV).exists())\n",
    "if GT_MIDI: print(Path(GT_MIDI).exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738dce8d",
   "metadata": {},
   "source": [
    "### Optional Overrides: Key / Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ce728",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_OVERRIDE = (\"C\", \"major\")  # e.g., (\"E\", \"minor\") or \"C major\"\n",
    "TEMPO_BPM = TEMPO_BPM if 'TEMPO_BPM' in globals() else None  # e.g., 96.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c6812",
   "metadata": {},
   "source": [
    "### Plotting Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa663c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal plotting functions with graceful fallback if matplotlib isn't installed.\n",
    "try:\n",
    "    import matplotlib.pyplot as plt  # type: ignore\n",
    "    _HAVE_MPL = True\n",
    "except Exception:  # pragma: no cover\n",
    "    plt = None\n",
    "    _HAVE_MPL = False\n",
    "\n",
    "\n",
    "def _head_finite(a: np.ndarray, k: int = 10) -> list:\n",
    "    if not isinstance(a, np.ndarray):\n",
    "        return []\n",
    "    af = a[np.isfinite(a)]\n",
    "    return [float(x) for x in af[:k]]\n",
    "\n",
    "\n",
    "def _tonic_name(i: int) -> str:\n",
    "    names = [\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"]\n",
    "    return names[int(i) % 12]\n",
    "\n",
    "\n",
    "def _time_axis(n_frames: int, hop: int, sr: int) -> np.ndarray:\n",
    "    return (np.arange(n_frames) * hop) / float(sr)\n",
    "\n",
    "\n",
    "def plot_wave(y: np.ndarray, sr: int, title: str = \"wave\") -> None:\n",
    "    if not _HAVE_MPL:\n",
    "        return\n",
    "    t = np.arange(len(y)) / float(sr)\n",
    "    plt.figure(figsize=(10, 2.5))\n",
    "    plt.plot(t, y, lw=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amp\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_track(t: np.ndarray, y: np.ndarray, title: str, ylabel: str) -> None:\n",
    "    if not _HAVE_MPL:\n",
    "        return\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(t, y, lw=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_two_tracks(t: np.ndarray, a: np.ndarray, b: np.ndarray, la: str, lb: str, title: str, ylabel: str) -> None:\n",
    "    if not _HAVE_MPL:\n",
    "        return\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(t, a, lw=0.8, label=la)\n",
    "    plt.plot(t, b, lw=0.8, label=lb)\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_onsets(t: np.ndarray, onsets_idx: np.ndarray, title: str = \"onsets\") -> None:\n",
    "    if not _HAVE_MPL:\n",
    "        return\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in onsets_idx[:200]:  # cap drawn lines\n",
    "        ts = float(t[int(i)]) if int(i) < len(t) else None\n",
    "        if ts is not None:\n",
    "            plt.axvline(ts, color=\"tomato\", alpha=0.6, lw=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_segments(segments: list[tuple[int, float, float, float]], title: str = \"segments\") -> None:\n",
    "    if not _HAVE_MPL:\n",
    "        return\n",
    "    plt.figure(figsize=(10, 2.5))\n",
    "    for midi, s, e, _ in segments:\n",
    "        plt.hlines(y=midi, xmin=s, xmax=e, colors=\"royalblue\", lw=3)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"MIDI\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_segments_compare(pred, gt, title: str = \"Pred vs GT (notes)\") -> None:\n",
    "    \"\"\"Plot predicted note segments vs ground truth for visual comparison.\n",
    "\n",
    "    pred: list of (midi, start, end[, rms]) or PrettyMIDI-like Note objects\n",
    "    gt:   list of _EvalNote or (start, end, midi)\n",
    "    \"\"\"\n",
    "    if not _HAVE_MPL:\n",
    "        return\n",
    "    def _to_triples(seq):\n",
    "        out = []\n",
    "        for x in seq:\n",
    "            if isinstance(x, tuple) or isinstance(x, list):\n",
    "                if len(x) >= 3:\n",
    "                    # allow (midi, start, end[, rms]) OR (start, end, midi)\n",
    "                    a, b, c = x[0], x[1], x[2]\n",
    "                    # Heuristic: if first looks like time (< 2000) but second < 2000 too, assume (midi,start,end)\n",
    "                    if isinstance(a, (int, float)) and isinstance(b, (int, float)) and isinstance(c, (int, float)):\n",
    "                        if a > 20 and a < 140 and b < c:  # likely (midi,start,end)\n",
    "                            out.append((int(a), float(b), float(c)))\n",
    "                        else:  # assume (start,end,midi)\n",
    "                            out.append((int(c), float(a), float(b)))\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                # object with attributes start,end,midi\n",
    "                try:\n",
    "                    out.append((int(x.midi), float(x.start), float(x.end)))\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return out\n",
    "\n",
    "    pred_tri = _to_triples(pred)\n",
    "    gt_tri = _to_triples(gt)\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 4.5), sharex=True)\n",
    "    axes[0].set_title(title)\n",
    "    \n",
    "    # Prediction\n",
    "    for m, s, e in pred_tri:\n",
    "        axes[1].hlines(y=m, xmin=s, xmax=e, colors=\"royalblue\", lw=3, label=None)\n",
    "        axes[2].hlines(y=m, xmin=s, xmax=e, colors=\"royalblue\", lw=3, label=None)\n",
    "    axes[1].set_ylabel(\"Pred MIDI\")\n",
    "    axes[1].set_xlabel(\"Time (s)\")\n",
    "    \n",
    "    # Ground truth\n",
    "    for m, s, e in gt_tri:\n",
    "        axes[0].hlines(y=m, xmin=s, xmax=e, colors=\"seagreen\", lw=3, label=None)\n",
    "        axes[2].hlines(y=m, xmin=s, xmax=e, colors=\"seagreen\", lw=3, label=None)\n",
    "    axes[0].set_ylabel(\"GT MIDI\")\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ffbe5",
   "metadata": {},
   "source": [
    "### Notebook Variables (shared across stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16c0e0",
   "metadata": {},
   "source": [
    "### Stage 0: Load → Condition → Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27006a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "if INPUT_WAV:\n",
    "    audio = load_mono(INPUT_WAV, sr=params.sr)\n",
    "    y0 = audio.y\n",
    "    yc = condition(y0, sr=audio.sr, hpf_cutoff=params.hpf_cutoff)\n",
    "    yn = normalize_rms(yc)\n",
    "    dur_s = len(y0) / params.sr if len(y0) else 0.0\n",
    "    rms0 = float(np.sqrt(np.mean(y0.astype(np.float64)**2))) if y0.size else 0.0\n",
    "    rms1 = float(np.sqrt(np.mean(yn.astype(np.float64)**2))) if yn.size else 0.0\n",
    "    print(f\"Loaded mono @ {params.sr} Hz, duration {dur_s:.2f} s, RMS {rms0:.6f} → post {rms1:.6f}\")\n",
    "    plot_wave(y0, params.sr, title=\"Wave (raw)\")\n",
    "    plot_wave(yn, params.sr, title=\"Wave (conditioned + normalized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f45d2e4",
   "metadata": {},
   "source": [
    "### Stage 1: f0 (YIN) + Confidence + Frame RMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'yn' in globals():\n",
    "    f0_hz, conf, rms_frames = f0_yin(\n",
    "        y=yn, sr=params.sr, frame=params.frame, hop=params.hop,\n",
    "        fmin_hz=params.fmin_hz, fmax_hz=params.fmax_hz,\n",
    "    )\n",
    "    print(\"Frames:\", len(f0_hz), \" f0 head(Hz):\", [round(x,2) for x in _head_finite(f0_hz)])\n",
    "    print(\"conf head:\", [round(x,3) for x in _head_finite(conf)])\n",
    "    t = _time_axis(len(f0_hz), params.hop, params.sr)\n",
    "    plot_track(t, f0_hz, title=\"f0 (raw)\", ylabel=\"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a7ff4d",
   "metadata": {},
   "source": [
    "### Stage 2: Voicing Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'f0_hz' in globals() and 'conf' in globals() and 'rms_frames' in globals():\n",
    "    voiced_mask = voice_mask_from_confidence(\n",
    "        f0_hz=f0_hz, voiced_conf=conf, frame_rms_vals=rms_frames,\n",
    "        min_confidence=params.min_confidence, min_rms_dbfs=params.min_rms_dbfs,\n",
    "    )\n",
    "    f0_voiced = f0_hz.copy(); f0_voiced[~voiced_mask] = np.nan\n",
    "    n_frames = len(voiced_mask)\n",
    "    n_voiced = int(np.sum(voiced_mask))\n",
    "    print(f\"Voiced frames: {n_voiced}/{n_frames} ({(100*n_voiced/max(1,n_frames)):.1f}%)\")\n",
    "    t = _time_axis(len(f0_hz), params.hop, params.sr)\n",
    "    plot_track(t, f0_voiced, title=\"f0 (Masked)\", ylabel=\"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa7e73",
   "metadata": {},
   "source": [
    "### Stage 3: Stabilize f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c8928",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'f0_voiced' in globals():\n",
    "    f0_stable = stabilize_f0(\n",
    "        f0_hz=f0_voiced, fmin_hz=params.fmin_hz, fmax_hz=params.fmax_hz,\n",
    "        median_k=params.median_k, ma_k=params.ma_k, guard_window=5, cents_tol=params.cents_tolerance,\n",
    "    )\n",
    "    med_f0 = float(np.nanmedian(f0_stable)) if np.isfinite(f0_stable).any() else float('nan')\n",
    "    print(\"f0_stable median:\", round(med_f0, 2), \"Hz\", \" head:\", [round(x,2) for x in _head_finite(f0_stable)])\n",
    "    t = _time_axis(len(f0_stable), params.hop, params.sr)\n",
    "    plot_two_tracks(t, f0_hz, f0_stable, la=\"raw\", lb=\"stable\", title=\"f0: raw vs stable\", ylabel=\"Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5609ae7",
   "metadata": {},
   "source": [
    "### Stage 4: Onsets (Spectral Flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'yn' in globals():\n",
    "    onsets = spectral_flux_onsets(y=yn, sr=params.sr, frame=params.frame, hop=params.hop, prom=params.onset_prom)\n",
    "    onsets_s = [round(frame_to_time(int(i), params.hop, params.sr), 3) for i in onsets[:10]]\n",
    "    print(\"Onsets count:\", len(onsets), \" first(s):\", onsets_s)\n",
    "    t = _time_axis(len(f0_hz) if 'f0_hz' in globals() else len(onsets), params.hop, params.sr)\n",
    "    plot_onsets(t, onsets, title=\"Onsets (vertical lines)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefffd24",
   "metadata": {},
   "source": [
    "### Stage 5: Map to MIDI Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b50e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'f0_stable' in globals():\n",
    "    midi_float = hz_to_midi(f0_stable)\n",
    "    print(\"midi_float head:\", [round(x,2) for x in _head_finite(midi_float)])\n",
    "    t = _time_axis(len(midi_float), params.hop, params.sr)\n",
    "    plot_track(t, midi_float, title=\"MIDI (float)\", ylabel=\"MIDI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bbf2da",
   "metadata": {},
   "source": [
    "### Stage 6: Hysteresis Rounding + Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'midi_float' in globals():\n",
    "    note_series = hysteresis_round(midi_float, params.debounce_frames, params.cents_tolerance)\n",
    "    seg_idx = segments_from_notes(note_series, min_note_frames=params.min_note_frames)\n",
    "    print(\"Segments:\", len(seg_idx), \" first:\", seg_idx[:5])\n",
    "    t = _time_axis(len(note_series), params.hop, params.sr)\n",
    "    plot_track(t, note_series, title=\"MIDI (integer with NaNs)\", ylabel=\"MIDI int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c85958",
   "metadata": {},
   "source": [
    "### Stage 7: Key Detection (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e14c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'seg_idx' in globals():\n",
    "    midi_list = [m for (m, s, e) in seg_idx]\n",
    "    key = estimate_key(midi_list) if (params.use_key_snap and midi_list) else None\n",
    "    override_used = False\n",
    "    if KEY_OVERRIDE:\n",
    "        key_override_est = key_override_to_estimate(KEY_OVERRIDE)\n",
    "        if key_override_est is not None:\n",
    "            key = key_override_est\n",
    "            override_used = True\n",
    "            print(f\"Key override applied: {_tonic_name(key.tonic)} {key.mode}\")\n",
    "        else:\n",
    "            print(\"Key override invalid, falling back to detected key.\")\n",
    "    if key is None:\n",
    "        print(\"Key: None / skipped\")\n",
    "    else:\n",
    "        if override_used:\n",
    "            print(\"Key (override):\", _tonic_name(key.tonic), key.mode)\n",
    "        else:\n",
    "            print(f\"Key: {_tonic_name(key.tonic)} {key.mode} (score={key.score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef8c98",
   "metadata": {},
   "source": [
    "### Stage 8: Timed Segments + Write MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ff444",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'seg_idx' in globals() and 'rms_frames' in globals():\n",
    "    segments = segments_to_timed(seg_idx, rms_frames, params)\n",
    "    if 'key' in globals() and key is not None and params.use_key_snap:\n",
    "        segments = apply_key_snap(segments, key)\n",
    "    \n",
    "    p = Path(INPUT_WAV)\n",
    "    midi_path = p.with_name(p.stem + \"_predicted\").with_suffix(\".mid\")\n",
    "    out_mid = OUT_MIDI if OUT_MIDI else str(midi_path)\n",
    "    write_midi(out_mid, segments, tempo_bpm=TEMPO_BPM)\n",
    "    print(f\"Wrote: {Path(out_mid).resolve()}\")\n",
    "    \n",
    "    if TEMPO_BPM:\n",
    "        print(f\"Tempo (override): {float(TEMPO_BPM):.2f} BPM\")\n",
    "    print(\"First 5 notes:\")\n",
    "    for row in segments[:5]:\n",
    "        print(\"  \", row)\n",
    "    plot_segments(segments, title=\"Exported notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc388f",
   "metadata": {},
   "source": [
    "### Listen: Audio (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cdc5a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from IPython.display import Audio as IPyAudio, display as ipy_display\n",
    "    _HAVE_IPY = True\n",
    "except Exception:  # pragma: no cover\n",
    "    _HAVE_IPY = False\n",
    "\n",
    "if _HAVE_IPY:\n",
    "    if 'y0' in globals():\n",
    "        print(\"Raw audio (y0): the original loaded signal\")\n",
    "        ipy_display(IPyAudio(data=y0, rate=params.sr))  # type: ignore\n",
    "    if 'yc' in globals():\n",
    "        print(\"Conditioned (yc): after DC blocker + high‑pass\")\n",
    "        ipy_display(IPyAudio(data=yc, rate=params.sr))  # type: ignore\n",
    "    if 'yn' in globals():\n",
    "        print(\"Normalized (yn): after RMS normalization\")\n",
    "        ipy_display(IPyAudio(data=yn, rate=params.sr))  # type: ignore\n",
    "    # Synthesized MIDI preview from detected segments (if available)\n",
    "    if 'segments' in globals():\n",
    "        try:\n",
    "            import pretty_midi\n",
    "            pm = pretty_midi.PrettyMIDI()\n",
    "            inst = pretty_midi.Instrument(program=0)\n",
    "            for midi, s, e, _rms in segments:\n",
    "                inst.notes.append(pretty_midi.Note(start=float(s), end=float(e), pitch=int(midi), velocity=80))\n",
    "            pm.instruments.append(inst)\n",
    "            try:\n",
    "                y_midi = pm.synthesize(fs=params.sr)\n",
    "            except Exception as e:\n",
    "                y_midi = None\n",
    "                print(e)\n",
    "            if y_midi is not None:\n",
    "                print(\"Synthesized MIDI (simple synth): renders the detected notes to audio\")\n",
    "                ipy_display(IPyAudio(data=y_midi.astype(np.float32, copy=False), rate=params.sr)) # type: ignore\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b24840",
   "metadata": {},
   "source": [
    "### Evaluation Helpers (pred vs. ground-truth MIDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd21c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class _EvalNote:\n",
    "    start: float\n",
    "    end: float\n",
    "    midi: int\n",
    "\n",
    "\n",
    "def _load_midi_notes(path: str) -> list[_EvalNote]:\n",
    "    import pretty_midi\n",
    "    pm = pretty_midi.PrettyMIDI(path)\n",
    "    notes: list[_EvalNote] = []\n",
    "    for inst in pm.instruments:\n",
    "        for n in inst.notes:\n",
    "            if n.end > n.start:\n",
    "                notes.append(_EvalNote(start=float(n.start), end=float(n.end), midi=int(n.pitch)))\n",
    "    notes.sort(key=lambda n: n.start)\n",
    "    return notes\n",
    "\n",
    "\n",
    "def _overlap_ratio(a: _EvalNote, b: _EvalNote) -> float:\n",
    "    inter = max(0.0, min(a.end, b.end) - max(a.start, b.start))\n",
    "    if inter <= 0:\n",
    "        return 0.0\n",
    "    denom = max(a.end - a.start, b.end - b.start)\n",
    "    return inter / denom if denom > 0 else 0.0\n",
    "\n",
    "\n",
    "def _cents_diff(midi_a: int, midi_b: int) -> float:\n",
    "    return 100.0 * abs(midi_a - midi_b)\n",
    "\n",
    "\n",
    "def eval_match_notes(\n",
    "    gt_mid: str,\n",
    "    pred_mid: str,\n",
    "    onset_ms: float = 50.0,\n",
    "    offset_ms: float = 50.0,\n",
    "    overlap_thr: float = 0.5,\n",
    "    pitch_cents: float = 50.0,\n",
    ") -> dict:\n",
    "    \"\"\"Evaluate predicted vs. ground-truth MIDI with extended metrics.\n",
    "\n",
    "    Adds onset-only F1 and duration error (ms) to the existing note F1 and\n",
    "    pitch error (cents). Uses greedy one-to-one matching for both note-level\n",
    "    and onset-only metrics.\n",
    "    \"\"\"\n",
    "    gt = _load_midi_notes(gt_mid)\n",
    "    pr = _load_midi_notes(pred_mid)\n",
    "\n",
    "    # ---------- Note-level matching (pitch + timing/overlap) ----------\n",
    "    used_pred: set[int] = set()\n",
    "    pairs: list[tuple[int, int]] = []\n",
    "    edges: list[tuple[float, int, int]] = []\n",
    "    for i, g in enumerate(gt):\n",
    "        for j, p in enumerate(pr):\n",
    "            # Pitch constraint in cents\n",
    "            if _cents_diff(g.midi, p.midi) > pitch_cents:\n",
    "                continue\n",
    "            # Timing/overlap rule\n",
    "            onset_ok = abs(p.start - g.start) <= (onset_ms / 1000.0)\n",
    "            offset_ok = abs(p.end - g.end) <= (offset_ms / 1000.0)\n",
    "            ov_ok = _overlap_ratio(g, p) >= overlap_thr\n",
    "            if not ((onset_ok and offset_ok) or ov_ok):\n",
    "                continue\n",
    "            # Cost: prefer better temporal alignment\n",
    "            cost = abs(p.start - g.start) + abs(p.end - g.end)\n",
    "            edges.append((cost, i, j))\n",
    "    edges.sort(key=lambda t: t[0])\n",
    "    used_gt: set[int] = set()\n",
    "    for _, i, j in edges:\n",
    "        if i in used_gt or j in used_pred:\n",
    "            continue\n",
    "        used_gt.add(i)\n",
    "        used_pred.add(j)\n",
    "        pairs.append((i, j))\n",
    "\n",
    "    tp = len(pairs)\n",
    "    fp = max(0, len(pr) - tp)\n",
    "    fn = max(0, len(gt) - tp)\n",
    "    P = tp / (tp + fp) if tp + fp > 0 else 0.0\n",
    "    R = tp / (tp + fn) if tp + fn > 0 else 0.0\n",
    "    F1 = 2 * P * R / (P + R) if P + R > 0 else 0.0\n",
    "\n",
    "    # Pitch error (cents) on matched pairs\n",
    "    cents_errs = [_cents_diff(gt[i].midi, pr[j].midi) for (i, j) in pairs]\n",
    "    mae_cents = float(np.mean(cents_errs)) if cents_errs else 0.0\n",
    "    med_cents = float(np.median(cents_errs)) if cents_errs else 0.0\n",
    "\n",
    "    # ---------- Onset-only matching (independent from note pairs) ----------\n",
    "    tol = onset_ms / 1000.0\n",
    "    onset_edges: list[tuple[float, int, int]] = []\n",
    "    for i, g in enumerate(gt):\n",
    "        for j, p in enumerate(pr):\n",
    "            d = abs(p.start - g.start)\n",
    "            if d <= tol:\n",
    "                onset_edges.append((d, i, j))\n",
    "    onset_edges.sort(key=lambda t: t[0])\n",
    "    used_gt_o: set[int] = set()\n",
    "    used_pred_o: set[int] = set()\n",
    "    onset_pairs: list[tuple[int, int]] = []\n",
    "    for _, i, j in onset_edges:\n",
    "        if i in used_gt_o or j in used_pred_o:\n",
    "            continue\n",
    "        used_gt_o.add(i)\n",
    "        used_pred_o.add(j)\n",
    "        onset_pairs.append((i, j))\n",
    "    tp_o = len(onset_pairs)\n",
    "    fp_o = max(0, len(pr) - tp_o)\n",
    "    fn_o = max(0, len(gt) - tp_o)\n",
    "    P_o = tp_o / (tp_o + fp_o) if tp_o + fp_o > 0 else 0.0\n",
    "    R_o = tp_o / (tp_o + fn_o) if tp_o + fn_o > 0 else 0.0\n",
    "    F1_o = 2 * P_o * R_o / (P_o + R_o) if P_o + R_o > 0 else 0.0\n",
    "\n",
    "    # ---------- Duration error (ms) on matched note pairs ----------\n",
    "    dur_errs_ms = [\n",
    "        abs((pr[j].end - pr[j].start) - (gt[i].end - gt[i].start)) * 1000.0\n",
    "        for (i, j) in pairs\n",
    "    ]\n",
    "    mae_dur_ms = float(np.mean(dur_errs_ms)) if dur_errs_ms else 0.0\n",
    "    med_dur_ms = float(np.median(dur_errs_ms)) if dur_errs_ms else 0.0\n",
    "\n",
    "    # Optional rounding for readability\n",
    "    def r4(x: float) -> float:\n",
    "        return float(np.round(x, 4))\n",
    "\n",
    "    return {\n",
    "        \"counts\": {\"gt\": len(gt), \"pred\": len(pr), \"tp\": tp, \"fp\": fp, \"fn\": fn},\n",
    "        \"note_f1\": {\"precision\": r4(P), \"recall\": r4(R), \"f1\": r4(F1)},\n",
    "        \"onset_f1\": {\"precision\": r4(P_o), \"recall\": r4(R_o), \"f1\": r4(F1_o)},\n",
    "        \"pitch_error_cents\": {\"mae\": r4(mae_cents), \"median\": r4(med_cents)},\n",
    "        \"duration_error_ms\": {\"mae\": r4(mae_dur_ms), \"median\": r4(med_dur_ms)},\n",
    "        \"params\": {\n",
    "            \"onset_ms\": onset_ms,\n",
    "            \"offset_ms\": offset_ms,\n",
    "            \"overlap_thr\": overlap_thr,\n",
    "            \"pitch_cents\": pitch_cents,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6dcb7",
   "metadata": {},
   "source": [
    "### Noise Robustness Evaluation (multi-SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bb60e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_with_noise_levels(\n",
    "    clean_wav: str,\n",
    "    gt_midi: str,\n",
    "    params: Params,\n",
    "    noise_levels_db: list[float] = [0, 10, 20],\n",
    "    render_audio: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"Evaluate the pipeline under multiple noise levels (in dB SNR).\n",
    "\n",
    "    Adds Gaussian white noise to a conditioned, clean input signal, renders each\n",
    "    noisy version (if available), transcribes with the existing pipeline, and\n",
    "    evaluates via `eval_match_notes()`.\n",
    "\n",
    "    Returns a dict mapping f\"{snr}dB\" → metrics dict.\n",
    "    \"\"\"\n",
    "    # Load and condition the clean audio\n",
    "    audio = load_mono(clean_wav, sr=params.sr)\n",
    "    y_clean = condition(audio.y, sr=audio.sr, hpf_cutoff=params.hpf_cutoff)\n",
    "\n",
    "    # Helper: add Gaussian noise at target SNR (dB)\n",
    "    def add_noise(y: np.ndarray, snr_db: float) -> np.ndarray:\n",
    "        rms_signal = float(np.sqrt(np.mean(np.square(y), dtype=np.float64)))\n",
    "        # Avoid division by zero for silent inputs\n",
    "        if rms_signal <= 1e-12:\n",
    "            return y.copy()\n",
    "        rms_noise = rms_signal / (10.0 ** (snr_db / 20.0))\n",
    "        noise = np.random.normal(0.0, rms_noise, size=y.shape)\n",
    "        out = y + noise.astype(y.dtype, copy=False)\n",
    "        return np.clip(out, -1.0, 1.0).astype(np.float32, copy=False)\n",
    "\n",
    "    # Workspace for temporary files\n",
    "    import tempfile\n",
    "    from pathlib import Path as _Path\n",
    "    tmpdir = _Path(tempfile.mkdtemp(prefix=\"s2m_noise_eval_\"))\n",
    "\n",
    "    results: dict[str, dict] = {}\n",
    "\n",
    "    # Try to enable inline audio rendering if in IPython\n",
    "    _can_render = False\n",
    "    if render_audio:\n",
    "        try:\n",
    "            from IPython.display import Audio as _IPyAudio, display as _ipy_display  # type: ignore\n",
    "            _can_render = True\n",
    "        except Exception:\n",
    "            _can_render = False\n",
    "\n",
    "    for snr in noise_levels_db:\n",
    "        # Generate noisy signal and normalize its RMS\n",
    "        y_noisy = add_noise(y_clean, float(snr))\n",
    "        y_noisy = normalize_rms(y_noisy)\n",
    "\n",
    "        # Save noisy audio to a temporary WAV\n",
    "        tag = (f\"{snr:g}\").replace(\".\", \"p\")\n",
    "        wav_path = tmpdir / f\"temp_snr{tag}.wav\"\n",
    "        midi_path = tmpdir / f\"temp_snr{tag}.mid\"\n",
    "        save_wav(str(wav_path), Audio(y=y_noisy, sr=params.sr))\n",
    "\n",
    "        # Optional inline audio rendering\n",
    "        if _can_render:\n",
    "            print(f\"SNR {snr:g} dB\")\n",
    "            try:\n",
    "                _ipy_display(_IPyAudio(data=y_noisy, rate=params.sr))  # type: ignore\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # Run pipeline and evaluate\n",
    "        _ = wav_to_midi_simple(str(wav_path), str(midi_path), params)\n",
    "        scores = eval_match_notes(gt_midi, str(midi_path))\n",
    "        results[f\"{snr:g}dB\"] = scores\n",
    "\n",
    "    # Print compact summary table\n",
    "    print(\"\\n--- Evaluation Summary ---\")\n",
    "    print(\"SNR | Note_F1 | Onset_F1 | Duration_MAE(ms)\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    def _get(d: dict, *keys: str, default: float = 0.0) -> float:\n",
    "        x = d\n",
    "        for k in keys:\n",
    "            if not isinstance(x, dict) or k not in x:\n",
    "                return default\n",
    "            x = x[k]\n",
    "        try:\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return default\n",
    "    for snr in noise_levels_db:\n",
    "        key = f\"{snr:g}dB\"\n",
    "        s = results.get(key, {})\n",
    "        note_f1 = _get(s, \"note_f1\", \"f1\")\n",
    "        onset_f1 = _get(s, \"onset_f1\", \"f1\")\n",
    "        dur_mae = _get(s, \"duration_error_ms\", \"mae\")\n",
    "        print(f\"{key:>4} | {note_f1:6.2f} | {onset_f1:8.2f} | {dur_mae:16.1f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb4cbd",
   "metadata": {},
   "source": [
    "### Multi-SNR Evaluation (example cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2983884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage in notebook or CLI cell\n",
    "CUSTOM_SNR_LEVELS = [-10, -5, 0, 5, 10, 20, 99]  # change here if needed\n",
    "if 'INPUT_WAV' in globals() and INPUT_WAV and 'GT_MIDI' in globals() and GT_MIDI:\n",
    "    try:\n",
    "        _noise_results = evaluate_with_noise_levels(INPUT_WAV, GT_MIDI, params, noise_levels_db=CUSTOM_SNR_LEVELS)\n",
    "    except Exception as _e:\n",
    "        print(_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077baf67",
   "metadata": {},
   "source": [
    "### Evaluation: compare predicted vs. ground-truth MIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure these before running this cell (optional overrides):\n",
    "EVAL_ONSET_MS = EVAL_ONSET_MS if 'EVAL_ONSET_MS' in globals() else 50.0\n",
    "EVAL_OFFSET_MS = EVAL_OFFSET_MS if 'EVAL_OFFSET_MS' in globals() else 50.0\n",
    "EVAL_OVERLAP = EVAL_OVERLAP if 'EVAL_OVERLAP' in globals() else 0.5\n",
    "EVAL_PITCH_CENTS = EVAL_PITCH_CENTS if 'EVAL_PITCH_CENTS' in globals() else 50.0\n",
    "\n",
    "# Resolve predicted MIDI path from earlier cells (Stage 8 or Quick Start)\n",
    "pred_mid = None\n",
    "if 'out_mid' in globals():\n",
    "    pred_mid = out_mid\n",
    "elif 'OUT_MIDI' in globals() and OUT_MIDI:\n",
    "    pred_mid = OUT_MIDI\n",
    "elif 'INPUT_WAV' in globals() and INPUT_WAV:\n",
    "    pred_mid = str(Path(INPUT_WAV).with_suffix('.mid'))\n",
    "\n",
    "if GT_MIDI and pred_mid:\n",
    "    scores = eval_match_notes(\n",
    "        gt_mid=GT_MIDI,\n",
    "        pred_mid=pred_mid,\n",
    "        onset_ms=EVAL_ONSET_MS,\n",
    "        offset_ms=EVAL_OFFSET_MS,\n",
    "        overlap_thr=EVAL_OVERLAP,\n",
    "        pitch_cents=EVAL_PITCH_CENTS,\n",
    "    )\n",
    "    print(json.dumps(scores, indent=2, sort_keys=True))\n",
    "    # Visual comparison (if matplotlib is available)\n",
    "    if _HAVE_MPL:\n",
    "        gt_notes = _load_midi_notes(GT_MIDI)\n",
    "        if 'segments' in globals() and segments:\n",
    "            pred_segs = [(m, s, e) for (m, s, e, _r) in segments]\n",
    "        else:\n",
    "            pr_notes = _load_midi_notes(pred_mid)\n",
    "            pred_segs = [(n.midi, n.start, n.end) for n in pr_notes]\n",
    "        plot_segments_compare(pred_segs, gt_notes, title=\"Pred vs GT (notes)\")\n",
    "    else:\n",
    "        print(\"Matplotlib not available. Skipping visual comparison.\")\n",
    "else:\n",
    "    if not GT_MIDI:\n",
    "        print(\"Set GT_MIDI to your ground-truth MIDI path.\")\n",
    "    if not pred_mid:\n",
    "        print(\"Set OUT_MIDI to your predicted MIDI path.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
